{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient descent\n",
    "\n",
    "- an optimization problem\n",
    "- also look into evolutionary algorithms\n",
    "- how to make use of it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_of_squares(v):\n",
    "    \"\"\"Computes the sum of squared elements in v\"\"\"\n",
    "    return sum(v_i ** 2 for v_i in v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delta y / delta x\n",
    "def difference_quotient(f, x, h):\n",
    "    return (f(x + h) - f(x)) / h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def square(x):\n",
    "    return x * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derivative(x):\n",
    "    return 2 * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "derivative_estimate = partial(difference_quotient, square, h=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x10d415470>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = range(-10, 10)\n",
    "plt.title('Actual Derivatives vs. Estimates')\n",
    "plt.plot(x, list(map(derivative, x)), 'rx', label='Actual')\n",
    "plt.plot(x, list(map(derivative_estimate, x)), 'b+', label='Estimate')\n",
    "plt.legend(loc=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partial_difference_quotient(f, v, i, h):\n",
    "    \"\"\"Compute the ith partial difference quotient of f at v\"\"\"\n",
    "    w = [v_j + (h if j == i else 0) # Add h to the ith element of v\n",
    "         for j, v_j in enumerate(v)]\n",
    "    return (f(w) - f(v)) / h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_gradient(f, v, h=0.00001):\n",
    "    return [partial_difference_quotient(f, v, i, h)\n",
    "            for i, _ in enumerate(v)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(v, direction, step_size):\n",
    "    \"\"\"Move step_size in the direction from v\"\"\"\n",
    "    return [v_i + step_size * direction_i \n",
    "            for v_i, direction_i in zip(v, direction)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_of_squares_gradient(v):\n",
    "    return [2 * v_i for v_i in v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def vector_subtract(v, w):\n",
    "    return [v_i - w_i\n",
    "            for v_i, w_i in zip(v, w)]\n",
    "\n",
    "def scalar_multiply(c, v):\n",
    "    return [c * v_i for v_i in v]\n",
    "\n",
    "def dot(v, w):\n",
    "    return sum(v_i * w_i for v_i, w_i in zip(v, w))\n",
    "\n",
    "def sum_of_squares(v):\n",
    "    return dot(v, v)\n",
    "\n",
    "def magnitude(v):\n",
    "    return math.sqrt(sum_of_squares(v))\n",
    "\n",
    "def distance(v, w):\n",
    "    return magnitude(vector_subtract(v, w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# Pick a random starting point.\n",
    "v = [random.randint(-10, 10) for i in range(3)]\n",
    "tolerance = 0.0000001\n",
    "while True:\n",
    "    gradient = sum_of_squares_gradient(v) # Compute the gradient at v.\n",
    "    next_v = step(v, gradient, -0.01) # Take a negative gradient step.\n",
    "    if distance(next_v, v) < tolerance: # Stop if we are converging.\n",
    "        break\n",
    "    v = next_v # Continue if we are not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.5964400041392797e-06, 2.39466000620892e-06, 3.991100010348203e-06]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing the right step size\n",
    "\n",
    "- using a fixed step size\n",
    "- gradually shrinking the step size over time\n",
    "- at each step, choosing the step size that minimizes the value of the objective function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_sizes = [100, 10, 1, 0.1, 0.01, 0.001, 0.00001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe(f):\n",
    "    \"\"\"Return a new function that's the same as f, except that it outputs infinity whenever f produces an error\"\"\"\n",
    "    def safe_f(*args, **kwargs):\n",
    "        try:\n",
    "            return f(*args, **kwargs)\n",
    "        except:\n",
    "            return float('inf')\n",
    "    return safe_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimize_batch(target_fn, gradient_fn, theta_0, tolerance=0.000001):\n",
    "    \"\"\"Use gradient descent to find theta that minimizes target function.\"\"\"\n",
    "    step_sizes = [100, 10, 1, 0.1, 0.01, 0.001, 0.0001, 0.000001]\n",
    "    \n",
    "    theta = theta_0 # Set theta to initial value.\n",
    "    target_fn = safe(target_fn)\n",
    "    value = target_fn(theta)\n",
    "    \n",
    "    while True:\n",
    "        gradient = gradient_fn(theta)\n",
    "        next_thetas = [step(theta, gradient, -step_size) \n",
    "                       for step_size in step_sizes]\n",
    "        \n",
    "        # Choose the one that minimizes the error function.\n",
    "        next_theta = min(next_thetas, key=target_fn)\n",
    "        next_value = target_fn(next_theta)\n",
    "        \n",
    "        # Stop if we are converging.\n",
    "        if abs(value - next_value) < tolerance:\n",
    "            return theta\n",
    "        else:\n",
    "            theta, value = next_theta, next_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negate(f):\n",
    "    \"\"\"Return a function that for any input x returns -f(x)\"\"\"\n",
    "    return lambda *args, **kwargs: -f(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negate_all(f):\n",
    "    \"\"\"The same when f returns a list of numbers\"\"\"\n",
    "    return lambda *args, **kwargs: [-y for y in f(*args, **kwargs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maximize_batch(target_fn, gradient_fn, theta_0, tolerance=0.000001):\n",
    "    return minimize_batch(negate(target_fn),\n",
    "                          negate_all(gradient_fn), \n",
    "                          theta_0,\n",
    "                          tolerance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_random_order(data):\n",
    "    \"\"\"Generator that returns the elements of data in random order\"\"\"\n",
    "    indexes = [i for i, _ in enumerate(data)] \n",
    "    random.shuffle(indexes)\n",
    "    for i in indexes:\n",
    "        yield data[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimize_stochastic(target_fn, gradient_fn, x, y, theta_0, alpha=0.01):\n",
    "    data = zip(x, y)\n",
    "    theta = theta_0\n",
    "    alpha = alpha_0\n",
    "    min_theta, min_value = None, float('inf')\n",
    "    iterations_with_no_improvement = 0\n",
    "    \n",
    "    # If we ever go 100 iterations with no improvements, stop.\n",
    "    while iterations_with_no_improvements < 100:\n",
    "        value = sum(target_fn(x_i, y_i, theta) for x_i, y_i in data)\n",
    "        \n",
    "        if value < min_value:\n",
    "            # If we found a new minimum, remember it and go back \n",
    "            # to the original step size\n",
    "            min_theta, min_value = theta, value\n",
    "            iterations_with_no_improvements = 0\n",
    "            alpha = alpha_0\n",
    "        else:\n",
    "            # Otherwise we are not improving, so try shrinking the step size.\n",
    "            iterations_with_no_improvements += 1\n",
    "            alpha *= 0.9\n",
    "        \n",
    "        # And take a gradient step for each of the data points.\n",
    "        for x_i, y_i in in_random_order(data):\n",
    "            gradient_i = gradient_fn(x_i, y_i, theta)\n",
    "            theta = vector_subtract(theta, scalar_multiply(alpha, gradient_i))\n",
    "    return min_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maximize_stochastic(target_fn, gradient_fn, x, y, theta_0, alpha_0=0.01):\n",
    "    return minimize_stochastic(negate(target_fn)\n",
    "                               negate_all(gradient_fn),\n",
    "                               x, y, theta_0, alpha_0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
