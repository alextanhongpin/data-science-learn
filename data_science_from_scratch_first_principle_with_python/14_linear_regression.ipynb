{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.linear_model import SGDRegressor, LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given the equation: y_i = B * x_i + A + e_i\n",
    "\n",
    "# Alpha is the intercept, beta is the weight. \n",
    "# Assuming we know alpha and beta for x_i we can calculate back y_i.\n",
    "def predict(alpha, beta, x_i):\n",
    "    return beta * x_i + alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error(alpha, beta, x_i, y_i):\n",
    "    \"\"\"The error from predicting beta * x_i + alpha when the actual value is y_i\"\"\"\n",
    "    return y_i - predict(alpha, beta, x_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_of_squared_errors(alpha, beta, x, y):\n",
    "    return sum(error(alpha, beta, x_i, y_i) ** 2\n",
    "               for x_i, y_i in zip(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def dot(v, w):\n",
    "    return sum(v_i * w_i\n",
    "               for v_i, w_i in zip(v, w))\n",
    "\n",
    "def sum_of_squares(v):\n",
    "    return dot(v, v)\n",
    "\n",
    "def vector_subtract(v, w):\n",
    "    return [v_i - w_i \n",
    "            for v_i, w_i in zip(v, w)]\n",
    "\n",
    "def squared_distance(v, w):\n",
    "    return sum_of_squares(vector_subtract(v, w))\n",
    "\n",
    "def magnitude(v):\n",
    "    return math.sqrt(sum_of_squares(v))\n",
    "\n",
    "def distance(v, w):\n",
    "    return math.sqrt()\n",
    "\n",
    "def shape(A):\n",
    "    num_rows = len(A)\n",
    "    num_cols = len(A[0]) if A else 0\n",
    "    return num_rows, num_cols\n",
    "\n",
    "def mean(x):\n",
    "    return sum(x) / len(x)\n",
    "\n",
    "def de_mean(x):\n",
    "    x_bar = mean(x)\n",
    "    return [x_i - x_bar \n",
    "            for x_i in x]\n",
    "\n",
    "def variance(x):\n",
    "    n = len(x)\n",
    "    deviations = de_mean(x)\n",
    "    return sum_of_squares(deviations) / (n - 1)\n",
    "\n",
    "def standard_deviation(x):\n",
    "    return math.sqrt(variance(x))\n",
    "\n",
    "def covariance(x, y):\n",
    "    n = len(x)\n",
    "    return dot(de_mean(x), de_mean(y)) / (n - 1)\n",
    "\n",
    "def correlation(x, y):\n",
    "    stdev_x = standard_deviation(x)\n",
    "    stdev_y = standard_deviation(y)\n",
    "    if stdev_x > 0 and stdev_y > 0:\n",
    "        return covariance(x, y) / stdev_x / stdev_y\n",
    "    return 0 # If no covariance, correlation is 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "def least_squares_fit(x, y):\n",
    "    \"\"\"Given training values for x and y, find the least-squares values of alpha and beta\"\"\"\n",
    "    beta = correlation(x, y) * standard_deviation(y) / standard_deviation(x)\n",
    "    alpha = mean(y) - beta * mean(x)\n",
    "    return alpha, beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22.94755241346903, 0.903865945605865)"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_friends_good = [49,41,40,25,21,21,19,19,18,18,16,15,15,15,15,14,14,13,13,13,13,12,12,11,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,8,8,8,8,8,8,8,8,8,8,8,8,8,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]\n",
    "daily_minutes_good = [68.77,51.25,52.08,38.36,44.54,57.13,51.4,41.42,31.22,34.76,54.01,38.79,47.59,49.1,27.66,41.03,36.73,48.65,28.12,46.62,35.57,32.98,35,26.07,23.77,39.73,40.57,31.65,31.21,36.32,20.45,21.93,26.02,27.34,23.49,46.94,30.5,33.8,24.23,21.4,27.94,32.24,40.57,25.07,19.42,22.39,18.42,46.96,23.72,26.41,26.97,36.76,40.32,35.02,29.47,30.2,31,38.11,38.18,36.31,21.03,30.86,36.07,28.66,29.08,37.28,15.28,24.17,22.31,30.17,25.53,19.85,35.37,44.6,17.23,13.47,26.33,35.02,32.09,24.81,19.33,28.77,24.26,31.98,25.73,24.86,16.28,34.51,15.23,39.72,40.8,26.06,35.76,34.76,16.13,44.04,18.03,19.65,32.62,35.59,39.43,14.18,35.24,40.13,41.82,35.45,36.07,43.67,24.61,20.9,21.9,18.79,27.61,27.21,26.61,29.77,20.59,27.53,13.82,33.2,25,33.1,36.65,18.63,14.87,22.2,36.81,25.53,24.62,26.25,18.21,28.08,19.42,29.79,32.8,35.99,28.32,27.79,35.88,29.06,36.28,14.1,36.63,37.49,26.9,18.58,38.48,24.48,18.95,33.55,14.24,29.04,32.51,25.63,22.22,19,32.73,15.16,13.9,27.2,32.01,29.27,33,13.74,20.42,27.32,18.23,35.35,28.48,9.08,24.62,20.12,35.26,19.92,31.02,16.49,12.16,30.7,31.22,34.65,13.13,27.51,33.2,31.57,14.1,33.42,17.44,10.12,24.42,9.82,23.39,30.93,15.03,21.67,31.09,33.29,22.61,26.89,23.48,8.38,27.81,32.35,23.84]\n",
    "\n",
    "alpha, beta = least_squares_fit(num_friends_good, daily_minutes_good)\n",
    "# alpha = 22.95 and beta = 0.903, which means a user with n friends will spend (22.95 + n * 0.903 minutes) minutes on the site each day.\n",
    "# Compare the value obtained with the one through stochastic gradient descent.\n",
    "alpha, beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_sum_of_squares(y):\n",
    "    \"\"\"The total squared variation of y_i's from their mean.\"\"\"\n",
    "    return sum(v ** 2 for v in de_mean(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_squared(alpha, beta, x, y):\n",
    "    \"\"\"The fraction of variation in y captured by the model, which equals 1 - the fraction of variation \n",
    "    in y not captured by the model.\"\"\"\n",
    "    return 1.0 - (sum_of_squared_errors(alpha, beta, x, y) /\n",
    "                  total_sum_of_squares(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3291078377836305"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_squared(alpha, beta, num_friends_good, daily_minutes_good) # 0.329"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squared_error(x_i, y_i, theta):\n",
    "    alpha, beta = theta\n",
    "    return error(alpha, beta, x_i, y_i) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squared_error_gradient(x_i, y_i, theta):\n",
    "    alpha, beta = theta\n",
    "    return [-2 * error(alpha, beta, x_i, y_i),       # alpha partial derivative.\n",
    "            -2 * error(alpha, beta, x_i, y_i) * x_i] # beta partial derivative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From vectors topic.\n",
    "\n",
    "def vector_subtract(v, w):\n",
    "    return [v_i - w_i \n",
    "            for v_i, w_i in zip(v, w)]\n",
    "\n",
    "def scalar_multiply(c, v):\n",
    "    \"\"\"c is a number, v is a vector\"\"\"\n",
    "    return [c * v_i for v_i in v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(0)\n",
    "\n",
    "def in_random_order(data):\n",
    "    \"\"\"Generator that returns the elements of data in random order.\"\"\"\n",
    "    indices = [i for i, _ in enumerate(data)] # Create a list of indexes.\n",
    "    random.shuffle(indices)\n",
    "    for i in indices:\n",
    "        yield data[i]\n",
    "\n",
    "def minimize_stochastic(target_fn, gradient_fn, x, y, theta_0, alpha_0=0.01):\n",
    "    # ! Without list(), this will turn out wrong.\n",
    "    data = list(zip(x, y))\n",
    "    theta = theta_0 # Initial guess.\n",
    "    alpha = alpha_0 # Initial step size.\n",
    "    min_theta, min_value = None, float('inf')\n",
    "    iterations_with_no_improvements = 0\n",
    "    \n",
    "    # If we ever go 100 iterations with no improvements, stop.\n",
    "    while iterations_with_no_improvements < 100:\n",
    "        value = sum(target_fn(x_i, y_i, theta) \n",
    "                    for x_i, y_i in data)\n",
    "        \n",
    "        if value < min_value:\n",
    "            # If we have found a minimum, remember it and go back to the original step size.\n",
    "            min_theta, min_value = theta, value\n",
    "            iterations_with_no_improvements = 0\n",
    "            alpha = alpha_0\n",
    "        else:\n",
    "            # Otherwise we are not improving, so try shrinking the step size.\n",
    "            iterations_with_no_improvements += 1\n",
    "            alpha *= 0.9\n",
    "        \n",
    "        # And take the gradient step for each of the data points.\n",
    "        for x_i, y_i in in_random_order(data):\n",
    "            gradient_i = gradient_fn(x_i, y_i, theta)\n",
    "            theta = vector_subtract(theta, scalar_multiply(alpha, gradient_i))\n",
    "\n",
    "    return min_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22.93746417548679, 0.9043371597664965)"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(0)\n",
    "\n",
    "theta = [random.random(), random.random()]\n",
    "alpha, beta = minimize_stochastic(squared_error, \n",
    "                                  squared_error_gradient,\n",
    "                                  num_friends_good,\n",
    "                                  daily_minutes_good,\n",
    "                                  theta,\n",
    "                                  0.000_1)\n",
    "\n",
    "# We get alpha = 22.93, and beta = 0.905.\n",
    "alpha, beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([49, 41, 40, 25, 21, 21, 19, 19, 18, 18],\n",
       " [68.77, 51.25, 52.08, 38.36, 44.54, 57.13, 51.4, 41.42, 31.22, 34.76])"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_friends_good[:10], daily_minutes_good[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
       "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
       "             learning_rate='invscaling', loss='squared_loss', max_iter=1000000,\n",
       "             n_iter_no_change=100, penalty='l2', power_t=0.25, random_state=42,\n",
       "             shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
       "             warm_start=False)"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wrong, should use SGDRegressor\n",
    "# clf = SGDClassifier(loss='squared_loss', tol=1e-3, max_iter=1000, random_state=42, shuffle=True)\n",
    "clf = SGDRegressor(max_iter=1000000, random_state=42, n_iter_no_change=100)\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(num_friends_good).reshape(-1, 1)\n",
    "y = np.array(daily_minutes_good, dtype=np.float64)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    train_size=0.9, \n",
    "                                                    random_state=42, \n",
    "                                                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((182, 1), (182,), (203, 1), (203,))"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
       "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
       "             learning_rate='invscaling', loss='squared_loss', max_iter=1000000,\n",
       "             n_iter_no_change=100, penalty='l2', power_t=0.25, random_state=42,\n",
       "             shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
       "             warm_start=False)"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([36.77726473, 40.63400389, 28.09960161, 30.02797119, 30.99215598,\n",
       "       31.95634077, 27.13541682, 25.20704724, 24.24286245, 25.20704724,\n",
       "       30.99215598, 26.17123203, 25.20704724, 24.24286245, 31.95634077,\n",
       "       24.24286245, 35.81307993, 30.02797119, 31.95634077, 26.17123203,\n",
       "       25.20704724])"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict = clf.predict(X_test)\n",
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11930321063523819"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.96418479]), array([23.27867766]), 288)"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coef_, clf.intercept_, clf.n_iter_ # The value will match if we fit it against X and y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With scikit-learn LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.8957493]), 23.29730704589147)"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LinearRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "y_predict = clf.predict(X_test)\n",
    "clf.coef_, clf.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15336654688869"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
