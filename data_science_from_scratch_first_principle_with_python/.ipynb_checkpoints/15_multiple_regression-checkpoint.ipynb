{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import SGDRegressor, LinearRegression, Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot(v, w):\n",
    "    return sum(v_i * w_i \n",
    "               for v_i, w_i in zip(v, w))\n",
    "\n",
    "def vector_subtract(v, w):\n",
    "    return [v_i - w_i for v_i, w_i in zip(v, w)]\n",
    "\n",
    "def scalar_multiply(c, v):\n",
    "    return [c * v_i for v_i in v]\n",
    "\n",
    "def predict(x_i, beta):\n",
    "    # Assumes that the first element of each x_i is 1.\n",
    "    return dot(x_i, beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [1,  # Constant term.\n",
    "     49, # Number of friends.\n",
    "     4,  # Work hours per day.\n",
    "     0]  # Doesn't have a phd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error(x_i, y_i, beta):\n",
    "    return y_i - predict(x_i, beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squared_error(x_i, y_i, beta):\n",
    "    return error(x_i, y_i, beta) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squared_error_gradient(x_i, y_i, beta):\n",
    "    \"\"\"The gradient (with respect to beta) corresponding to the ith squared error term.\"\"\"\n",
    "    return [-2 * x_ij * error(x_i, y_i, beta)\n",
    "            for x_ij in x_i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From gradient_descent chapter.\n",
    "random.seed(0)\n",
    "\n",
    "def in_random_order(data):\n",
    "    indices = [i for i, _ in enumerate(data)]\n",
    "    random.shuffle(indices)\n",
    "    for i in indices:\n",
    "        yield data[i]\n",
    "\n",
    "def minimize_stochastic(target_fn, gradient_fn, x, y, theta_0, alpha_0 = 0.01):\n",
    "    data = list(zip(x, y))\n",
    "    theta = theta_0\n",
    "    alpha = alpha_0\n",
    "    min_value, min_theta = float('inf'), None\n",
    "    iterations_with_no_improvements = 0\n",
    "    \n",
    "    while iterations_with_no_improvements < 100:\n",
    "        value = sum(target_fn(x_i, y_i, theta)\n",
    "                    for x_i, y_i in data)\n",
    "        \n",
    "        if value < min_value:\n",
    "            min_theta, min_value = theta, value\n",
    "            iterations_with_no_improvements = 0\n",
    "            alpha = alpha_0\n",
    "        else:\n",
    "            iterations_with_no_improvements += 1\n",
    "            alpha *= 0.9\n",
    "        \n",
    "        for x_i, y_i in in_random_order(data):\n",
    "            gradient_i = gradient_fn(x_i, y_i, theta)\n",
    "            theta = vector_subtract(theta, scalar_multiply(alpha, gradient_i))\n",
    "    \n",
    "    return min_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "\n",
    "def estimate_beta(x, y):\n",
    "    beta_initial = [random.random() for x_i in x[0]]\n",
    "    return minimize_stochastic(squared_error,\n",
    "                               squared_error_gradient,\n",
    "                               x, y,\n",
    "                               beta_initial,\n",
    "                               0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[30.499077157914908,\n",
       " 0.9769330063220196,\n",
       " -1.8598894301433166,\n",
       " 0.9709279958984955]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [[1,49,4,0],[1,41,9,0],[1,40,8,0],[1,25,6,0],[1,21,1,0],[1,21,0,0],[1,19,3,0],[1,19,0,0],[1,18,9,0],[1,18,8,0],[1,16,4,0],[1,15,3,0],[1,15,0,0],[1,15,2,0],[1,15,7,0],[1,14,0,0],[1,14,1,0],[1,13,1,0],[1,13,7,0],[1,13,4,0],[1,13,2,0],[1,12,5,0],[1,12,0,0],[1,11,9,0],[1,10,9,0],[1,10,1,0],[1,10,1,0],[1,10,7,0],[1,10,9,0],[1,10,1,0],[1,10,6,0],[1,10,6,0],[1,10,8,0],[1,10,10,0],[1,10,6,0],[1,10,0,0],[1,10,5,0],[1,10,3,0],[1,10,4,0],[1,9,9,0],[1,9,9,0],[1,9,0,0],[1,9,0,0],[1,9,6,0],[1,9,10,0],[1,9,8,0],[1,9,5,0],[1,9,2,0],[1,9,9,0],[1,9,10,0],[1,9,7,0],[1,9,2,0],[1,9,0,0],[1,9,4,0],[1,9,6,0],[1,9,4,0],[1,9,7,0],[1,8,3,0],[1,8,2,0],[1,8,4,0],[1,8,9,0],[1,8,2,0],[1,8,3,0],[1,8,5,0],[1,8,8,0],[1,8,0,0],[1,8,9,0],[1,8,10,0],[1,8,5,0],[1,8,5,0],[1,7,5,0],[1,7,5,0],[1,7,0,0],[1,7,2,0],[1,7,8,0],[1,7,10,0],[1,7,5,0],[1,7,3,0],[1,7,3,0],[1,7,6,0],[1,7,7,0],[1,7,7,0],[1,7,9,0],[1,7,3,0],[1,7,8,0],[1,6,4,0],[1,6,6,0],[1,6,4,0],[1,6,9,0],[1,6,0,0],[1,6,1,0],[1,6,4,0],[1,6,1,0],[1,6,0,0],[1,6,7,0],[1,6,0,0],[1,6,8,0],[1,6,4,0],[1,6,2,1],[1,6,1,1],[1,6,3,1],[1,6,6,1],[1,6,4,1],[1,6,4,1],[1,6,1,1],[1,6,3,1],[1,6,4,1],[1,5,1,1],[1,5,9,1],[1,5,4,1],[1,5,6,1],[1,5,4,1],[1,5,4,1],[1,5,10,1],[1,5,5,1],[1,5,2,1],[1,5,4,1],[1,5,4,1],[1,5,9,1],[1,5,3,1],[1,5,10,1],[1,5,2,1],[1,5,2,1],[1,5,9,1],[1,4,8,1],[1,4,6,1],[1,4,0,1],[1,4,10,1],[1,4,5,1],[1,4,10,1],[1,4,9,1],[1,4,1,1],[1,4,4,1],[1,4,4,1],[1,4,0,1],[1,4,3,1],[1,4,1,1],[1,4,3,1],[1,4,2,1],[1,4,4,1],[1,4,4,1],[1,4,8,1],[1,4,2,1],[1,4,4,1],[1,3,2,1],[1,3,6,1],[1,3,4,1],[1,3,7,1],[1,3,4,1],[1,3,1,1],[1,3,10,1],[1,3,3,1],[1,3,4,1],[1,3,7,1],[1,3,5,1],[1,3,6,1],[1,3,1,1],[1,3,6,1],[1,3,10,1],[1,3,2,1],[1,3,4,1],[1,3,2,1],[1,3,1,1],[1,3,5,1],[1,2,4,1],[1,2,2,1],[1,2,8,1],[1,2,3,1],[1,2,1,1],[1,2,9,1],[1,2,10,1],[1,2,9,1],[1,2,4,1],[1,2,5,1],[1,2,0,1],[1,2,9,1],[1,2,9,1],[1,2,0,1],[1,2,1,1],[1,2,1,1],[1,2,4,1],[1,1,0,1],[1,1,2,1],[1,1,2,1],[1,1,5,1],[1,1,3,1],[1,1,10,1],[1,1,6,1],[1,1,0,1],[1,1,8,1],[1,1,6,1],[1,1,4,1],[1,1,9,1],[1,1,9,1],[1,1,4,1],[1,1,2,1],[1,1,9,1],[1,1,0,1],[1,1,8,1],[1,1,6,1],[1,1,1,1],[1,1,1,1],[1,1,5,1]]\n",
    "daily_minutes_good = [68.77,51.25,52.08,38.36,44.54,57.13,51.4,41.42,31.22,34.76,54.01,38.79,47.59,49.1,27.66,41.03,36.73,48.65,28.12,46.62,35.57,32.98,35,26.07,23.77,39.73,40.57,31.65,31.21,36.32,20.45,21.93,26.02,27.34,23.49,46.94,30.5,33.8,24.23,21.4,27.94,32.24,40.57,25.07,19.42,22.39,18.42,46.96,23.72,26.41,26.97,36.76,40.32,35.02,29.47,30.2,31,38.11,38.18,36.31,21.03,30.86,36.07,28.66,29.08,37.28,15.28,24.17,22.31,30.17,25.53,19.85,35.37,44.6,17.23,13.47,26.33,35.02,32.09,24.81,19.33,28.77,24.26,31.98,25.73,24.86,16.28,34.51,15.23,39.72,40.8,26.06,35.76,34.76,16.13,44.04,18.03,19.65,32.62,35.59,39.43,14.18,35.24,40.13,41.82,35.45,36.07,43.67,24.61,20.9,21.9,18.79,27.61,27.21,26.61,29.77,20.59,27.53,13.82,33.2,25,33.1,36.65,18.63,14.87,22.2,36.81,25.53,24.62,26.25,18.21,28.08,19.42,29.79,32.8,35.99,28.32,27.79,35.88,29.06,36.28,14.1,36.63,37.49,26.9,18.58,38.48,24.48,18.95,33.55,14.24,29.04,32.51,25.63,22.22,19,32.73,15.16,13.9,27.2,32.01,29.27,33,13.74,20.42,27.32,18.23,35.35,28.48,9.08,24.62,20.12,35.26,19.92,31.02,16.49,12.16,30.7,31.22,34.65,13.13,27.51,33.2,31.57,14.1,33.42,17.44,10.12,24.42,9.82,23.39,30.93,15.03,21.67,31.09,33.29,22.61,26.89,23.48,8.38,27.81,32.35,23.84]\n",
    "\n",
    "# [30.63, 0.972, -1.868, 0.911]\n",
    "beta = estimate_beta(x, daily_minutes_good)\n",
    "beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example with scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(x)\n",
    "y = np.array(daily_minutes_good)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    train_size=0.9,\n",
    "                                                    random_state=42,\n",
    "                                                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.2731473692897881\n",
      "score: 0.6197256000655169\n",
      "intercept (alpha): 30.78653648761638\n",
      "coef (beta): [ 0.          0.95769925 -1.85323958  1.02762303]\n"
     ]
    }
   ],
   "source": [
    "clf = LinearRegression(normalize=True)\n",
    "clf.fit(X_train, y_train)\n",
    "y_predict = clf.predict(X_test)\n",
    "print(f'score: {r2_score(y_predict, y_test)}')\n",
    "print(f'score: {clf.score(X_test, y_test)}')\n",
    "print(f'intercept (alpha): {clf.intercept_}')\n",
    "print(f'coef (beta): {clf.coef_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.50263184, 0.62954358, 0.51511305, 0.50334486, 0.38508339])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LinearRegression(normalize=True)\n",
    "cross_val_score(clf, X, y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.27313631884885714\n",
      "score: 0.6198283156747679\n",
      "intercept (alpha): 30.812390900450843\n",
      "coef (beta): [ 0.          0.95592662 -1.8522071   0.99235951]\n"
     ]
    }
   ],
   "source": [
    "clf = Ridge()\n",
    "clf.fit(X_train, y_train)\n",
    "y_predict = clf.predict(X_test)\n",
    "print(f'score: {r2_score(y_predict, y_test)}')\n",
    "print(f'score: {clf.score(X_test, y_test)}')\n",
    "print(f'intercept (alpha): {clf.intercept_}')\n",
    "print(f'coef (beta): {clf.coef_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: -0.10673858585758134\n",
      "score: 0.5488802790694427\n",
      "intercept (alpha): [11.92686738]\n",
      "coef (beta): [11.92345059  1.31819685 -1.40931819  6.23032603]\n"
     ]
    }
   ],
   "source": [
    "clf = SGDRegressor(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "y_predict = clf.predict(X_test)\n",
    "print(f'score: {r2_score(y_predict, y_test)}')\n",
    "print(f'score: {clf.score(X_test, y_test)}')\n",
    "print(f'intercept (alpha): {clf.intercept_}')\n",
    "print(f'coef (beta): {clf.coef_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean(v):\n",
    "    return sum(v) / len(v)\n",
    "\n",
    "def de_mean(x):\n",
    "    x_bar = mean(x)\n",
    "    return [x_i - x_bar for x_i in x]\n",
    "\n",
    "def total_sum_of_squares(y):\n",
    "    return sum([v ** 2 for v in de_mean(y)])\n",
    "\n",
    "def multiple_r_squared(x, y, beta):\n",
    "    sum_of_squared_errors = sum(error(x_i, y_i, beta) ** 2\n",
    "                                for x_i, y_i in zip(x, y))\n",
    "    return 1.0 - sum_of_squared_errors / total_sum_of_squares(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6800074955952597"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The r-squared value, which is 0.68.\n",
    "multiple_r_squared(x, daily_minutes_good, beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_sample(data):\n",
    "    \"\"\"Randomly samples len(data) elements with replacements.\"\"\"\n",
    "    return [random.choice(data) for _ in data]\n",
    "\n",
    "def bootstrap_statistic(data, stats_fn, num_samples):\n",
    "    \"\"\"Evaluates stats_fn on num_samples bootstrap samples from data.\"\"\"\n",
    "    return [stats_fn(bootstrap_sample(data))\n",
    "            for _ in range(num_samples)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From statistics chapter.\n",
    "\n",
    "def median(v):\n",
    "    \"\"\"Find the middle-most value of v.\"\"\"\n",
    "    n = len(v)\n",
    "    sorted_v = sorted(v)\n",
    "    midpoint = n // 2\n",
    "    \n",
    "    if n % 2 == 1:\n",
    "        # If odd, return the middle value.\n",
    "        return sorted_v[midpoint]\n",
    "    else:\n",
    "        # If even, return the average of the middle values.\n",
    "        lo = midpoint - 1\n",
    "        hi = midpoint\n",
    "        return (sorted_v[lo] + sorted_v[hi]) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 101 points all very close to 100.\n",
    "close_to_100 = [99.5 + random.random() for _ in range(101)]\n",
    "\n",
    "# 101 points, 50 of them near 0, 50 of them near 200.\n",
    "far_from_100 = ([99.5 + random.random()] +\n",
    "                [random.random() for _ in range(50)] + \n",
    "                [200 + random.random() for _ in range(50)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[100.02634537429101,\n",
       " 100.06586584030461,\n",
       " 100.06850285070729,\n",
       " 100.06586584030461,\n",
       " 100.08022923777746]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bootstrap_statistic(close_to_100, median, 100)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9746929609488131,\n",
       " 0.9746929609488131,\n",
       " 0.9632764195933914,\n",
       " 200.0254523027627,\n",
       " 200.03723940374888]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bootstrap_statistic(far_from_100, median, 100)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_sample_beta(sample):\n",
    "    \"\"\"Sample is a list of pairs (x_i, y_i).\"\"\"\n",
    "    x_sample, y_sample = zip(*sample)\n",
    "    return estimate_beta(x_sample, y_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "bootstrap_betas = bootstrap_statistic(list(zip(x, daily_minutes_good)), \n",
    "                                      estimate_sample_beta,\n",
    "                                      100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "bootstrap_standard_errors = [statistics.stdev([beta[i] for beta in bootstrap_betas])\n",
    "                             for i in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From chapter probability.\n",
    "import math\n",
    "\n",
    "def normal_cdf(x, mu=0, sigma=1):\n",
    "    return (1 + math.erf((x - mu) / math.sqrt(2) / sigma)) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_value(beta_hat_j, sigma_hat_j):\n",
    "    if beta_hat_j > 0:\n",
    "        # If the coefficient is positive, we need to compute twice the \n",
    "        # probability of seeing an even *larger* value.\n",
    "        return 2 * (1 - normal_cdf(beta_hat_j / sigma_hat_j))\n",
    "    else:\n",
    "        # Otherwise twice the probability of seeing a *smaller* value.\n",
    "        return 2 * normal_cdf(beta_hat_j, sigma_hat_j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_value(30.63, 1.174) # ~0 (constant term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_value(0.972, 0.079) # ~0 (num_friends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04560835386531781"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_value(-1.868, 0.131) # ~0 (work_hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35746719881669264"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_value(0.911, 0.990) # 0.36 (phd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization\n",
    "\n",
    "An approach in which we add to the error term a penalty that gets larger as beta gets larger. We then minimize the combined error and penalty. \n",
    "\n",
    "### Ridge regression\n",
    "\n",
    "Adds a penalty proportional to the sum of the squares of the beta_i. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha is the *hyperparamater* controlling how harsh the penalty is \n",
    "# sometimes it is called \"lambda\" but that already means something in python.\n",
    "def ridge_penalty(beta, alpha):\n",
    "    return alpha * dot(beta[1:], beta[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squared_error_ridge(x_i, y_i, beta, alpha):\n",
    "    \"\"\"Estimate error plus ridge penalty on beta.\"\"\"\n",
    "    return error(x_i, y_i, beta) ** 2 + ridge_penalty(beta, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The ridge regression can be plugged into gradient descent the usual way.\n",
    "def ridge_penalty_gradient(beta, alpha):\n",
    "    \"\"\"Gradient of just the ridge penalty.\"\"\"\n",
    "    return [0] + [2 * alpha * beta_j for beta_j in beta[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_add(v, w):\n",
    "    return [v_i + w_i for v_i, w_i in zip(v, w)]\n",
    "\n",
    "def squared_error_ridge_gradient(x_i, y_i, beta, alpha):\n",
    "    \"\"\"The gradient corresponding to the ith squared error term including the ridge penalty.\"\"\"\n",
    "    return vector_add(squared_error_gradient(x_i, y_i, beta),\n",
    "                      ridge_penalty_gradient(beta, alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "def estimate_beta_ridge(x, y, alpha):\n",
    "    \"\"\"Use gradient descent to fit a ridge regression with penalty alpha.\"\"\"\n",
    "    beta_initial = [random.random() for x_i in x[0]]\n",
    "    return minimize_stochastic(partial(squared_error_ridge, alpha=alpha),\n",
    "                               partial(squared_error_ridge_gradient, \n",
    "                                       alpha=alpha),\n",
    "                               x, y,\n",
    "                               beta_initial,\n",
    "                               0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[30.619881701311712,\n",
       " 0.9702056472470465,\n",
       " -1.8671913880379478,\n",
       " 0.9163711597955347]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(0)\n",
    "\n",
    "beta_0 = estimate_beta_ridge(x, daily_minutes_good, alpha=0.0)\n",
    "beta_0 # [30.6, 0.97, -1.87, 0.91]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.267438780018153"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot(beta_0[1:], beta_0[1:]) # 5.26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6800074955952597"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiple_r_squared(x, daily_minutes_good, beta_0) # 0.680"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[30.55985204967343,\n",
       " 0.9730655363505671,\n",
       " -1.8624424625144256,\n",
       " 0.9317665551046306]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As we increase alpha, the goodness of fit gets worse, but the size of beta gets smaller.\n",
    "beta_0_01 = estimate_beta_ridge(x, daily_minutes_good, alpha=0.01)\n",
    "beta_0_01 # [30.6, 0.97, -1.86, 0.93]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.2837373774215655"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot(beta_0_01[1:], beta_0_01[1:]) # 5.17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.680010213297079"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiple_r_squared(x, daily_minutes_good, beta_0_01) # 0.680"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[30.894860179735474,\n",
       " 0.9490275238632391,\n",
       " -1.8501720889216575,\n",
       " 0.5325129720515789]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As we increase alpha, the goodness of fit gets worse, but the size of beta gets smaller.\n",
    "beta_0_1 = estimate_beta_ridge(x, daily_minutes_good, alpha=0.1)\n",
    "beta_0_1 # [30.8, 0.95, -1.84, 0.54]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.607360065077926"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot(beta_0_1[1:], beta_0_1[1:]) # 4.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6797276241305292"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiple_r_squared(x, daily_minutes_good, beta_0_1) # 0.680"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
