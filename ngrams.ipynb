{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word frequency, unigrams, bigrams and trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package alpino to\n",
      "[nltk_data]     /Users/alextanhongpin/nltk_data...\n",
      "[nltk_data]   Package alpino is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['De', 'verzekeringsmaatschappijen', 'verhelen', ...]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "nltk.download('alpino')\n",
    "from nltk.corpus import alpino\n",
    "alpino.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('De',)\n",
      "('verzekeringsmaatschappijen',)\n",
      "('verhelen',)\n",
      "('niet',)\n",
      "('dat',)\n",
      "('ook',)\n",
      "('de',)\n",
      "('rentegrondslag',)\n",
      "('van',)\n",
      "('vier',)\n",
      "('procent',)\n"
     ]
    }
   ],
   "source": [
    "unigrams = ngrams(alpino.words(), 1)\n",
    "row = 0\n",
    "for i in unigrams:\n",
    "    print(i)\n",
    "    row += 1\n",
    "    if row > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('De', 'verzekeringsmaatschappijen', 'verhelen', 'niet')\n",
      "('verzekeringsmaatschappijen', 'verhelen', 'niet', 'dat')\n",
      "('verhelen', 'niet', 'dat', 'ook')\n",
      "('niet', 'dat', 'ook', 'de')\n",
      "('dat', 'ook', 'de', 'rentegrondslag')\n",
      "('ook', 'de', 'rentegrondslag', 'van')\n",
      "('de', 'rentegrondslag', 'van', 'vier')\n",
      "('rentegrondslag', 'van', 'vier', 'procent')\n",
      "('van', 'vier', 'procent', 'nog')\n",
      "('vier', 'procent', 'nog', 'een')\n",
      "('procent', 'nog', 'een', 'ruime')\n"
     ]
    }
   ],
   "source": [
    "quadgrams = ngrams(alpino.words(), 4)\n",
    "row = 0\n",
    "for i in quadgrams:\n",
    "    print(i)\n",
    "    row += 1\n",
    "    if row > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package webtext to\n",
      "[nltk_data]     /Users/alextanhongpin/nltk_data...\n",
      "[nltk_data]   Package webtext is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.collocations import BigramCollocationFinder\n",
    "nltk.download('webtext')\n",
    "from nltk.corpus import webtext\n",
    "from nltk.metrics import BigramAssocMeasures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [t.lower() for t in webtext.words('grail.txt')]\n",
    "words = BigramCollocationFinder.from_words(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"'\", 's'),\n",
       " ('arthur', ':'),\n",
       " ('#', '1'),\n",
       " (\"'\", 't'),\n",
       " ('villager', '#'),\n",
       " ('#', '2'),\n",
       " (']', '['),\n",
       " ('1', ':'),\n",
       " ('oh', ','),\n",
       " ('black', 'knight')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.nbest(BigramAssocMeasures.likelihood_ratio, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import webtext\n",
    "from nltk.collocations import BigramCollocationFinder \n",
    "from nltk.metrics import BigramAssocMeasures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('black', 'knight'),\n",
       " ('clop', 'clop'),\n",
       " ('head', 'knight'),\n",
       " ('mumble', 'mumble'),\n",
       " ('squeak', 'squeak'),\n",
       " ('saw', 'saw'),\n",
       " ('holy', 'grail'),\n",
       " ('run', 'away'),\n",
       " ('french', 'guard'),\n",
       " ('cartoon', 'character')]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwordsset = set(stopwords.words('english'))\n",
    "\n",
    "# Exclude if the length is less than 3 or if it is a stopword.\n",
    "stops_filter = lambda w: len(w) < 3 or w in stopwordsset\n",
    "\n",
    "# Lowercase all the words first.\n",
    "tokens = [t.lower() for t in webtext.words('grail.txt')]\n",
    "words = BigramCollocationFinder.from_words(tokens)\n",
    "words.apply_word_filter(stops_filter)\n",
    "freq = 10\n",
    "words.nbest(BigramAssocMeasures.likelihood_ratio, freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating bigrams from a text using collocation finders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('.', 'Never'),\n",
       " ('Hardwork', 'is'),\n",
       " ('Never', 'give'),\n",
       " ('give', 'up'),\n",
       " ('is', 'the'),\n",
       " ('key', 'to'),\n",
       " ('success', '.'),\n",
       " ('the', 'key'),\n",
       " ('to', 'success'),\n",
       " ('up', '!')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.collocations import BigramCollocationFinder, BigramAssocMeasures\n",
    "\n",
    "text = 'Hardwork is the key to success. Never give up!'\n",
    "word = nltk.wordpunct_tokenize(text)\n",
    "finder = BigramCollocationFinder.from_words(word)\n",
    "bigram_measures = BigramAssocMeasures()\n",
    "value = finder.score_ngrams(bigram_measures.raw_freq)\n",
    "sorted(bigram for bigram, score in value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating bigrams using ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('De', 'verzekeringsmaatschappijen')\n",
      "('verzekeringsmaatschappijen', 'verhelen')\n",
      "('verhelen', 'niet')\n",
      "('niet', 'dat')\n",
      "('dat', 'ook')\n",
      "('ook', 'de')\n",
      "('de', 'rentegrondslag')\n",
      "('rentegrondslag', 'van')\n",
      "('van', 'vier')\n",
      "('vier', 'procent')\n",
      "('procent', 'nog')\n"
     ]
    }
   ],
   "source": [
    "from nltk.util import ngrams\n",
    "from nltk.corpus import alpino\n",
    "bigrams = ngrams(alpino.words(), 2)\n",
    "count = 0\n",
    "for i in bigrams:\n",
    "    print(i)\n",
    "    count += 1\n",
    "    if count > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating frequency of quadgrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import wordpunct_tokenize\n",
    "from nltk.collocations import QuadgramCollocationFinder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Hello', 'how', 'are', 'you') 1\n",
      "('how', 'are', 'you', 'doing') 1\n",
      "('are', 'you', 'doing', '?') 1\n",
      "('you', 'doing', '?', 'I') 1\n",
      "('doing', '?', 'I', 'hope') 1\n",
      "('?', 'I', 'hope', 'you') 1\n",
      "('I', 'hope', 'you', 'find') 1\n",
      "('hope', 'you', 'find', 'the') 1\n",
      "('you', 'find', 'the', 'book') 1\n",
      "('find', 'the', 'book', 'interesting') 1\n"
     ]
    }
   ],
   "source": [
    "text = \"Hello how are you doing ? I hope you find the book interesting\"\n",
    "tokens = wordpunct_tokenize(text)\n",
    "fourgrams = QuadgramCollocationFinder.from_words(tokens)\n",
    "for fourgram, freq in fourgrams.ngram_fd.items():\n",
    "    print(fourgram, freq)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
